use actix_web::{post, web, HttpResponse, Responder};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;

use crate::ollama_client::OllamaResponse;

/// ç³»ç»Ÿå‚æ•°è®¾å®šè¯·æ±‚
#[derive(Debug, Clone, Deserialize)]
pub struct SetSystemPromptRequest {
    /// ä¼šè¯ IDï¼ˆå¯é€‰ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub session_id: Option<String>,
    /// ç³»ç»Ÿå‚æ•°ï¼ˆå¿…é¡»ï¼‰
    pub system_prompt: String,
}

/// ç³»ç»Ÿå‚æ•°è®¾å®šå“åº”
#[derive(Debug, Clone, Serialize)]
pub struct SetSystemPromptResponse {
    pub status: String,
    pub message: OllamaResponse,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub session_id: Option<String>,
}

/// Ollama è¯·æ±‚ä½“
#[derive(Debug, Clone, Serialize)]
struct OllamaSystemRequest {
    model: String,
    prompt: String,
    system: String,
    stream: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    context: Option<Vec<i64>>,
}

/// Ollama å“åº”ä½“ï¼ˆä½¿ç”¨ ollama_client æ¨¡å—ä¸­çš„å®šä¹‰ï¼‰

/// ä¼šè¯å­˜å‚¨ç»“æ„
pub struct SessionStore {
    sessions: Arc<RwLock<HashMap<String, Vec<i64>>>>,
}

impl SessionStore {
    pub fn new() -> Self {
        Self {
            sessions: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    /// è·å–ä¼šè¯ä¸Šä¸‹æ–‡
    async fn get_context(&self, session_id: &str) -> Option<Vec<i64>> {
        let sessions = self.sessions.read().await;
        sessions.get(session_id).cloned()
    }

    /// ä¿å­˜ä¼šè¯ä¸Šä¸‹æ–‡
    async fn save_context(&self, session_id: String, context: Vec<i64>) {
        let mut sessions = self.sessions.write().await;
        sessions.insert(session_id, context);
    }
}

/// è®¾å®šæ¨¡å‹ç³»ç»Ÿå‚æ•°
/// 
/// POST /api/system-prompt
/// 
/// è¯·æ±‚ä½“ï¼š
/// ```json
/// {
///   "session_id": "optional-session-id",
///   "system_prompt": "ä½ æ˜¯ä¸€ä¸ªhelpfulçš„AIåŠ©æ‰‹"
/// }
/// ```
#[post("/api/system-prompt")]
pub async fn set_system_prompt(
    request: web::Json<SetSystemPromptRequest>,
    session_store: web::Data<Arc<SessionStore>>,
) -> impl Responder {
    let session_id = request.session_id.clone().unwrap_or_else(|| {
        // å¦‚æœæ²¡æœ‰æä¾› session_idï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„
        uuid::Uuid::new_v4().to_string()
    });

    // æˆªå–ç³»ç»Ÿæç¤ºçš„å‰20ä¸ªå­—ç¬¦ç”¨äºæ—¥å¿—æ˜¾ç¤º
    let prompt_preview = if request.system_prompt.len() > 20 {
        &request.system_prompt[..20]
    } else {
        &request.system_prompt
    };
    
    log::info!(
        "ğŸ“ è®¾å®šç³»ç»Ÿå‚æ•° - ä¼šè¯ID: {}, ç³»ç»Ÿæç¤º: {}",
        session_id,
        prompt_preview
    );

    // è·å–ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    let context = session_store.get_context(&session_id).await;

    // ä»ç¯å¢ƒå˜é‡è·å– Ollama é…ç½®
    let ollama_host = std::env::var("OLLAMA_HOST").unwrap_or_else(|_| "127.0.0.1".to_string());
    let ollama_port = std::env::var("OLLAMA_PORT").unwrap_or_else(|_| "11434".to_string());
    let ollama_url = format!("http://{}:{}/api/generate", ollama_host, ollama_port);

    // è·å–é»˜è®¤æ¨¡å‹
    let model = std::env::var("OLLAMA_MODEL").unwrap_or_else(|_| "gpt-oss:20b".to_string());

    // æ„é€  Ollama è¯·æ±‚
    let ollama_request = OllamaSystemRequest {
        model,
        prompt: prompt_preview.to_string(), // ç®€å•çš„ç¡®è®¤æ¶ˆæ¯
        system: request.system_prompt.clone(),
        stream: false,
        context,
    };
    log::info!("Ollama è¯·æ±‚: {:?}", ollama_request);
    // å‘é€ HTTP è¯·æ±‚åˆ° Ollama
    let client = reqwest::Client::new();
    match client
        .post(&ollama_url)
        .json(&ollama_request)
        .send()
        .await
    {
        Ok(response) => {
            let response = response.text().await.unwrap();
            log::info!("Ollama å“åº”: {}", response);

            match serde_json::from_str::<OllamaResponse>(&response) {
                Ok(ollama_response) => {
                    // è®°å½•æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
                    let stats = ollama_response.performance_stats();
                    log::info!("âœ… Ollama å“åº”æˆåŠŸ: {:?}", ollama_response);
                    log::info!("ğŸ“Š æ€§èƒ½ç»Ÿè®¡: {}", stats.format_summary());
                    
                    // å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œè®°å½•å®ƒ
                    if ollama_response.has_thinking() {
                        log::debug!("ğŸ§  æ€è€ƒè¿‡ç¨‹: {}", ollama_response.thinking.as_ref().unwrap());
                    }

                    // ä¿å­˜ä¼šè¯ä¸Šä¸‹æ–‡
                    if let Some(new_context) = &ollama_response.context {
                        session_store
                            .save_context(session_id.clone(), new_context.clone().to_vec())
                            .await;
                        log::debug!("ğŸ’¾ ä¿å­˜ä¼šè¯ä¸Šä¸‹æ–‡ - ä¼šè¯ID: {}", session_id);
                    }

                    HttpResponse::Ok().json(SetSystemPromptResponse {
                        status: "success".to_string(),
                        message: ollama_response,
                        session_id: Some(session_id),
                    })
                }
                Err(e) => {
                    log::error!("âŒ è§£æ Ollama å“åº”å¤±è´¥: {}", e);
                    HttpResponse::InternalServerError().json(serde_json::json!({
                        "error": format!("è§£æ Ollama å“åº”å¤±è´¥: {}", e)
                    }))
                }
            }
        }
        Err(e) => {
            log::error!("âŒ è¯·æ±‚ Ollama å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "error": format!("è¯·æ±‚ Ollama å¤±è´¥: {}", e)
            }))
        }
    }
}

